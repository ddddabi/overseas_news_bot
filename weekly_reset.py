import os
import pandas as pd
from datetime import datetime
from utils import load_config, init_sheet, send_webhook
import logging

# ë¡œê¹… ì„¤ì •
os.makedirs("logs", exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("logs/weekly_reset.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def main():
    cfg = load_config()
    send_webhook("ğŸ§¹ [Weekly Reset] ì‹œíŠ¸ ë°±ì—… ë° ì´ˆê¸°í™” ì‹œì‘", cfg)

    spreadsheet = init_sheet(cfg)
    target_sheets = ["All News", "Filtered News"]
    backup_dir = os.path.join(os.getcwd(), "backups")
    os.makedirs(backup_dir, exist_ok=True)

    today = datetime.utcnow().strftime("%m-%d")

    for sheet_name in target_sheets:
        try:
            sheet = spreadsheet.worksheet(sheet_name)
            records = sheet.get_all_records()
            if not records:
                logging.warning(f"âš ï¸ '{sheet_name}' ì‹œíŠ¸ì— ë°±ì—…í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            df = pd.DataFrame(records)
            filename = f"{sheet_name.replace(' ', '_')}_{today}.csv"
            backup_path = os.path.join(backup_dir, filename)

            df.to_csv(backup_path, index=False, encoding='utf-8-sig')
            logging.info(f"ğŸ“ '{sheet_name}' ì‹œíŠ¸ ë°±ì—… ì™„ë£Œ: {backup_path}")

            sheet.clear()
            sheet.update([df.columns.tolist()])
            logging.info(f"ğŸ§¹ '{sheet_name}' ì‹œíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ.")
        except Exception as e:
            logging.error(f"âŒ '{sheet_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    send_webhook("âœ… [Weekly Reset] ëª¨ë“  ì‹œíŠ¸ ë°±ì—… ë° ì´ˆê¸°í™” ì™„ë£Œ", cfg)

if __name__ == "__main__":
    main()
